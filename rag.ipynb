{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ğŸ“š LangChain ile Retrieval Augmented Generation'a GiriÅŸ ğŸ¦œğŸ”—\n",
    "\n",
    "Bu not defterinde LangChain kullanarak Retrieval Augmented Generation'Ä± nasÄ±l kullanacaÄŸÄ±nÄ±zÄ± Ã¶ÄŸreneceksiniz.\n",
    "\n",
    "Kendi belgelerimiz hakkÄ±nda sorular sormak iÃ§in bir LLM kullanacaÄŸÄ±z!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âš™ï¸ Kurulum\n",
    "\n",
    "ğŸ‘‰ Temel kÃ¼tÃ¼phaneleri iÃ§e aktarmak iÃ§in aÅŸaÄŸÄ±daki hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "from pprint import pprint\n",
    "from IPython.display import Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ API anahtarÄ±mÄ±zÄ± tekrar yÃ¼klemek iÃ§in aÅŸaÄŸÄ±daki hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()  # Load environment variables from .env file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“š Neden RAG?\n",
    "\n",
    "Bir LLM kendi baÅŸÄ±na, Ã¶ÄŸrendiÄŸi her ÅŸey hakkÄ±nda sorulara yanÄ±t verebilir.\n",
    "\n",
    "Bunun birkaÃ§ dezavantajÄ± vardÄ±r:\n",
    "- EÄŸitim verileri geÃ§miÅŸten gelir ve en son verilerle gÃ¼ncellenmez.\n",
    "- Sadece eÄŸitim aldÄ±ÄŸÄ± verileri bilir.\n",
    "\n",
    "Bir LLM'yi kendi verilerimizle Ã§alÄ±ÅŸmasÄ± iÃ§in kullanmak istiyoruz. Ä°ÅŸte bu noktada RAG (Retrieval-Augmented Generation) devreye girer.\n",
    "\n",
    "1. **Retrieval-Augmented Generation (RAG)**, gerÃ§ek doÄŸruluÄŸu artÄ±rmak iÃ§in bir dil modelini belge alÄ±cÄ± ile birleÅŸtirir.\n",
    "2. **Ä°lgili dÄ±ÅŸ belgeleri alÄ±r** (Ã¶rneÄŸin, bilgi tabanÄ±ndan) yanÄ±tlar Ã¼retmeden Ã¶nce.\n",
    "3. **Dil modeli hem istemi hem de alÄ±nan baÄŸlamÄ± kullanarak** daha bilgili ve temelli Ã§Ä±ktÄ±lar Ã¼retir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ‡ªğŸ‡º BaÄŸlam\n",
    "\n",
    "Bu meydan okumada, Avrupa Parlamentosu'ndan belgelerle Ã§alÄ±ÅŸacaÄŸÄ±z.\n",
    "\n",
    "Bir gazeteci olduÄŸunuzu ve Avrupa Parlamentosu'nun genel kurul oturumlarÄ± sÄ±rasÄ±nda belirli bir konu hakkÄ±nda neler sÃ¶ylendiÄŸini Ã¶ÄŸrenmek istediÄŸinizi dÃ¼ÅŸÃ¼nÃ¼n. Bu oturumlar yÄ±lda 12 kez Strasbourg'da gerÃ§ekleÅŸir ve 4 gÃ¼n sÃ¼rer. OturumlarÄ±n transkriptleri EP'nin web sitesinde mevcuttur.\n",
    "\n",
    "Kesinlikle tÃ¼m bu transkriptleri karÄ±ÅŸtÄ±rmak istemezsiniz. O halde, hayatÄ±mÄ±zÄ± kolaylaÅŸtÄ±rmak iÃ§in RAG'Ä± kullanalÄ±m!\n",
    "\n",
    "Bu, her zaman test etmek iÃ§in yepyeni veriler alabileceÄŸimiz iÃ§in Ã§alÄ±ÅŸmak Ã¼zere iyi verilerdir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ“˜ Verileri alalÄ±m\n",
    "\n",
    "1. [EP'nin web sitesine](https://www.europarl.europa.eu/plenary/en/debates-video.html) gidin. \n",
    "1. Bu sizi en son genel kurul oturumuna yÃ¶nlendirecektir.\n",
    "1. Ä°lk tarihin altÄ±nda, \"â–¶ï¸ Verbatim reports HTML\" bÃ¶lÃ¼mÃ¼nde `HTML`'e tÄ±klayÄ±n.\n",
    "1. SayfanÄ±n sonuna kaydÄ±rÄ±n ve alttaki PDF dosyasÄ±nÄ± indirin.\n",
    "1. DosyayÄ± `data` klasÃ¶rÃ¼ne kaydedin.\n",
    "\n",
    "Bir belgeyle baÅŸlayacaÄŸÄ±z, ancak daha sonrasÄ± iÃ§in diÄŸer birkaÃ§ gÃ¼nÃ¼n aynÄ±sÄ±nÄ± ÅŸimdiden indirebilirsiniz.\n",
    "\n",
    "Belgeye bir gÃ¶z atÄ±n. KaÃ§ sayfasÄ± var? Belge hakkÄ±nda bir fikir edinmek iÃ§in hÄ±zlÄ±ca belgede gezinin."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ”¢ Belgeleri gÃ¶mme\n",
    "\n",
    "Belgeleri gÃ¶mmek, tÃ¼m belgeleri veya belge parÃ§alarÄ±nÄ± vektÃ¶rlere Ã§evirmek anlamÄ±na gelir.\n",
    "\n",
    "LangChainğŸ¦œğŸ”— yine Ã§ok yardÄ±mcÄ± olacak.\n",
    "\n",
    "Bir gÃ¶mme aracÄ± (embedder) baÅŸlatalÄ±m ve deneyelim. LLM olarak Gemini kullandÄ±ÄŸÄ±mÄ±z iÃ§in, Google'Ä±n metin gÃ¶mme araÃ§larÄ±nda kalalÄ±m."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "\n",
    "embeddings = GoogleGenerativeAIEmbeddings(model=\"models/gemini-embedding-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Basit bir metin parÃ§asÄ±nÄ± gÃ¶mmek iÃ§in gÃ¶mme aracÄ±nÄ±n `.embed_query()` metodunu deneyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "steps"
    ]
   },
   "outputs": [],
   "source": [
    "# Embed a text like \"What is the capital of France?\" and save it to a variable `sample_embedding`\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Bu `sample_embedding`'i keÅŸfetmek iÃ§in zaman ayÄ±rÄ±n. NasÄ±l gÃ¶rÃ¼nÃ¼yor? Tipi nedir? GÃ¶mme boyutu nedir?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ PDF'den gerÃ§ek verilerimizi yÃ¼kle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArtÄ±k bir gÃ¶mmenin nasÄ±l gÃ¶rÃ¼ndÃ¼ÄŸÃ¼nÃ¼ biliyoruz, gerÃ§ek verilerimizle Ã§alÄ±ÅŸmanÄ±n zamanÄ± geldi.\n",
    "\n",
    "ğŸ‘‰ [LangChain belgelerine](https://docs.langchain.com/oss/python/integrations/document_loaders/index#pdfs) gidin ve PyPDF kullanarak bir PDF'yi nasÄ±l yÃ¼kleyebileceÄŸinizi Ã¶ÄŸrenin.\n",
    "\n",
    "ğŸ‘‰ Sonra devam edin ve daha Ã¶nce indirdiÄŸiniz PDF'lerden birini yÃ¼kleyin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ `pages`'i keÅŸfedin:\n",
    "- Veri tipi nedir?\n",
    "- KaÃ§ sayfanÄ±z var?\n",
    "- Bir sayfanÄ±n tipi nedir?\n",
    "- Bir sayfanÄ±n iÃ§eriÄŸine nasÄ±l eriÅŸebilirsiniz?\n",
    "- Tam belgenin kaÃ§ karakteri var?\n",
    "- Bir sayfanÄ±n `metadata`'sÄ±nda neler var?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## âœ‚ï¸ Verilerimizi bÃ¶l\n",
    "\n",
    "Tam belgemiz gÃ¶mÃ¼lmek iÃ§in Ã§ok uzun. Metin gÃ¶mme aracÄ±mÄ±z 2.048 tokena kadar giriÅŸ alabilir. Gemini modelleri iÃ§in bu yaklaÅŸÄ±k 8.196 karakterdir (token baÅŸÄ±na 4 karakter).\n",
    "\n",
    "Bu yÃ¼zden belgemizi daha kÃ¼Ã§Ã¼k parÃ§alara bÃ¶lmek istiyoruz.\n",
    "\n",
    "Zaten Ã§alÄ±ÅŸabileceÄŸimiz bir dizi sayfamÄ±z var. Ama sayfa sonlarÄ± biraz keyfi: genellikle cÃ¼mlenin ortasÄ±nda gÃ¶rÃ¼nÃ¼rler.\n",
    "\n",
    "AyrÄ±ca, sayfalar arasÄ±nda Ã¶rtÃ¼ÅŸme yoktur. Bu yÃ¼zden bir sayfanÄ±n ilk satÄ±rÄ± Ã¶nceki tÃ¼m baÄŸlamÄ± kaÃ§Ä±rÄ±r. Tam metni biraz Ã¶rtÃ¼ÅŸmeyle bÃ¶lmek daha iyidir."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ä°lk olarak, PDF'yi tekrar yÃ¼kleyeceÄŸiz, bu sefer bÃ¶lmeden."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = PyPDFLoader(file_path, mode='single')\n",
    "pdf = loader.load()\n",
    "pdf_text = pdf[0].page_content\n",
    "len(pdf_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ArtÄ±k tÃ¼m PDF'imizi tek bir belge olarak aldÄ±ÄŸÄ±mÄ±za gÃ¶re, onu daha akÄ±llÄ± bir ÅŸekilde parÃ§alara bÃ¶lebiliriz.\n",
    "\n",
    "ğŸ‘‰ Yine, [\"Ã–zyinelemeli olarak bÃ¶lme\" konusundaki LangChain belgelerine](https://docs.langchain.com/oss/python/integrations/splitters/recursive_text_splitter) gidin ve `pdf` _belgelerimizi_ parÃ§alara (LangChain'de `documents` olarak adlandÄ±rÄ±lÄ±r) nasÄ±l bÃ¶leceÄŸinizi Ã¶ÄŸrenin.\n",
    "\n",
    "2_000 karakter (bizim durumumuzda yaklaÅŸÄ±k yarÄ±m sayfa) parÃ§alara 400 Ã¶rtÃ¼ÅŸmeyle bÃ¶lÃ¼n. Ä°sterseniz diÄŸer deÄŸerlerle deneyebilirsiniz.\n",
    "\n",
    "`RecursiveCharacterTextSplitter`'Ä±n `.split_documents()` metodunu kullanÄ±n: bu metod giriÅŸ olarak bir belge alÄ±r ve bÃ¶lÃ¼nmÃ¼ÅŸ belgeler Ã§Ä±ktÄ±sÄ± verir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ `all_splits`'i inceleyin:\n",
    "- Veri tipi nedir?\n",
    "- KaÃ§ bÃ¶lÃ¼mÃ¼nÃ¼z var?\n",
    "- Bir bÃ¶lÃ¼mÃ¼n tipi nedir?\n",
    "- Bir bÃ¶lÃ¼mÃ¼n iÃ§eriÄŸine nasÄ±l eriÅŸebilirsiniz?\n",
    "- Åimdi toplamda kaÃ§ karakterimiz var?\n",
    "- Bir bÃ¶lÃ¼mÃ¼n `metadata`'sÄ±nda neler var?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ—„ï¸ Her ÅŸeyi bir araya getir: belgelerimizi gÃ¶mme ve vektÃ¶r deposunda sakla\n",
    "\n",
    "Elimizde ÅŸunlar var:\n",
    "- Bir gÃ¶mme aracÄ±\n",
    "- Veriyi yÃ¼klemek iÃ§in bir yÃ¼kleyici\n",
    "- Belgemizi belgelere bÃ¶lmek iÃ§in bir metin bÃ¶lÃ¼cÃ¼\n",
    "\n",
    "Neyi kaÃ§Ä±rÄ±yoruz?\n",
    "\n",
    "Belgelerimizi gÃ¶mebiliriz, ama onlarÄ± bir yerde saklamak istiyoruz. Ä°ÅŸte burada vektÃ¶r deposu devreye girer: ÅŸunlarÄ± saklamamÄ±za olanak saÄŸlar:\n",
    "- belgeyi (parÃ§ayÄ±),\n",
    "- onun gÃ¶mmesini,\n",
    "- meta verilerini.\n",
    "\n",
    "Sonraki adÄ±mda belgeleri verimli bir ÅŸekilde alabilecek olacaÄŸÄ±z.\n",
    "\n",
    "ğŸ‘‰ Bir `InMemoryVectorStore` nasÄ±l oluÅŸturabileceÄŸinizi gÃ¶rmek iÃ§in [\"VektÃ¶r depolarÄ±\" Ã¼zerine LangChain belgelerini](https://docs.langchain.com/oss/python/langchain/knowledge-base#3-vector-stores) kontrol edin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "steps"
    ]
   },
   "outputs": [],
   "source": [
    "# Import the necessary libraries\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Create an in-memory vector store using the embedder `embeddings` we created earlier\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Add the `all_splits` to the vector store and store the result in a variable called `document_ids`\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "steps"
    ]
   },
   "outputs": [],
   "source": [
    "# Have a look at the first 3 document IDs\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "steps"
    ]
   },
   "outputs": [],
   "source": [
    "# Use the vector store's `get_by_ids` method. You have to give it a list of document IDs.\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Bir vektÃ¶r deposundaki belgenin iÃ§eriÄŸine ve meta verilerine nasÄ±l eriÅŸebilirsiniz?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ” Benzer belgeleri almak iÃ§in vektÃ¶r deposunu kullan\n",
    "\n",
    "ArtÄ±k belgeleri gÃ¶mleÄŸe Ã§evirdiÄŸimize gÃ¶re, benzer belgeleri almak iÃ§in vektÃ¶r deposunu kullanabiliriz.\n",
    "\n",
    "ğŸ‘‰ Bunun nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± gÃ¶rmek iÃ§in [\"VektÃ¶r depolarÄ±\" Ã¼zerine LangChain belgelerini](https://docs.langchain.com/oss/python/langchain/knowledge-base#3-vector-stores) kontrol edin.\n",
    "\n",
    "Bir sorgu kullanÄ±n, Ã¶rneÄŸin \"TarÄ±m politikasÄ± Ã¼zerine tartÄ±ÅŸmayÄ± Ã¶zetle.\", ve en benzer belgeleri bulun. AyrÄ±ca alÄ±nacak belge sayÄ±sÄ±nÄ± da belirtebilirsiniz."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "steps"
    ]
   },
   "outputs": [],
   "source": [
    "# Save your question into a variable called `query`\n",
    "\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Use the vector store to find similar documents to the query. Store the result in a variable called `retrieved_docs`\n",
    "\n",
    "# YOUR CODE HERE\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu, RAG'Ä±n sÃ¶zde \"Alma\" (Retrieval) kÄ±smÄ±nÄ± tamamlar: artÄ±k sorgumuza en benzer belgeleri bulabiliriz.\n",
    "\n",
    "Ã‡alÄ±ÅŸmanÄ±n Ã§oÄŸu artÄ±k tamamlandÄ±!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¬ Sorumuza bir cevap Ã¼ret\n",
    "\n",
    "Åimdiye kadar benzer belgeleri almamÄ±zÄ± saÄŸlamak iÃ§in sadece bir **gÃ¶mme modeli** kullandÄ±k.\n",
    "\n",
    "Åimdi, sorumuzla bir cevap almak iÃ§in Ã¼retici bir LLM kullanacaÄŸÄ±z: ona aldÄ±ÄŸÄ±mÄ±z belgeler ve sorumuzla besleyeceÄŸiz.\n",
    "\n",
    "Bunu yapmanÄ±n en temel yolu tÃ¼m girdilerimizi birbirine baÄŸlamak, sorumuzla eklemek ve sonucu gÃ¶rmek olacaktÄ±r.\n",
    "\n",
    "Bir deneyelim.\n",
    "\n",
    "ğŸ‘‰ Ä°lk olarak Ã¶nceki meydan okumalarda olduÄŸu gibi bir LLM baÅŸlatÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sonra temel bir istem oluÅŸturun:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = '\\n\\n'.join([doc.page_content for doc in retrieved_docs])\n",
    "prompt += \"\\n\\n\" + query"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Åimdi istemi kullanÄ±n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bu fena deÄŸil, ama modele daha fazla rehberlik vererek daha kapsamlÄ± bir istem yazarak daha iyisini yapabiliriz.\n",
    "\n",
    "Bunu yapan ilk kiÅŸiler biz deÄŸilmiÅŸiz ve LangChain'in bizim iÃ§in Ã¶nceden hazÄ±rlanmÄ±ÅŸ istem kÃ¼tÃ¼phanesi var.\n",
    "\n",
    "ğŸ‘‰ AÅŸaÄŸÄ±daki hÃ¼creyi Ã§alÄ±ÅŸtÄ±rÄ±n ve nasÄ±l Ã§alÄ±ÅŸtÄ±ÄŸÄ±nÄ± anlamaya Ã§alÄ±ÅŸÄ±n. (LangSmithMissingAPIKeyWarning hakkÄ±nda bir uyarÄ± alacaksÄ±nÄ±z, bunu gÃ¶rmezden gelebilirsiniz.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_classic import hub\n",
    "\n",
    "prompt_template = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "example_messages = prompt_template.invoke(\n",
    "    {\"context\": \"(context goes here)\", \"question\": \"(question goes here)\"}\n",
    ").to_messages()\n",
    "\n",
    "print(\"\\n\")\n",
    "print(example_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain'in bizim iÃ§in nasÄ±l daha kesin bir istem oluÅŸturduÄŸunu gÃ¶rÃ¼yor musunuz? Bunu RAG'Ä±mÄ±z iÃ§in kullanalÄ±m!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Ä°lk olarak, tÃ¼m alÄ±nan belgeleri iki yeni satÄ±rla ayrÄ±lmÄ±ÅŸ tek bir uzun dizgiye birleÅŸtirin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Sonra, sorgunuz ve alÄ±nan belgelerden baÅŸlayarak bir `prompt` oluÅŸturun. YukarÄ±daki Ã¶rneÄŸe bakmayÄ± unutmayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Son olarak az Ã¶nce oluÅŸturduÄŸumuz `the_prompt` ile LLM modelini kullanÄ±n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‰ Ä°lk RAG'Ä±mÄ±zÄ± tamamladÄ±k: LLM kendisine saÄŸladÄ±ÄŸÄ±mÄ±z belgelerde ***temelli*** metin Ã¼retti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ğŸ’¾ GÃ¶mmelerimizi kalÄ±cÄ± hale getir\n",
    "\n",
    "Åimdiye kadar bellekte vektÃ¶r deposuyla Ã§alÄ±ÅŸtÄ±k. Bu yÃ¼zden not defterinizi kapattÄ±ÄŸÄ±nÄ±zda, tÃ¼m gÃ¶mmeleri de kaybedeceksiniz.\n",
    "\n",
    "âš ï¸ Bu gÃ¶mmelerin saÄŸlayÄ±cÄ±nÄ±zÄ±n platformunda, bu durumda Google'Ä±n makinelerinde Ã§alÄ±ÅŸan modeller tarafÄ±ndan Ã¼retildiÄŸini unutmayÄ±n. Ve bedava Ã§alÄ±ÅŸmazlar. ğŸ’°\n",
    "\n",
    "Bunun gibi bir, nispeten kÃ¼Ã§Ã¼k belge iÃ§in maliyet dÃ¼ÅŸÃ¼ktÃ¼r, ama hÄ±zla artar. Åimdiye kadar sadece bir gÃ¼nÃ¼n transkriptleriyle Ã§alÄ±ÅŸtÄ±k. Oturum baÅŸÄ±na 3 tane daha, yÄ±lda 12 oturum, birden fazla yÄ±l var...\n",
    "\n",
    "Bunu Ã§Ã¶zmek iÃ§in sadece vektÃ¶r depomuzla kalÄ±cÄ± bir taneyi deÄŸiÅŸtireceÄŸiz. Bu LangChain'in avantajÄ±dÄ±r: bileÅŸenleri deÄŸiÅŸtirmek Ã§ok kolay.\n",
    "\n",
    "Bellekteki vektÃ¶r depomuz deneme iÃ§in harikaydÄ±, ÅŸimdi baÅŸka bir taneyle deÄŸiÅŸtireceÄŸiz. Ã‡ok popÃ¼ler bir vektÃ¶r deposu olan [Chroma](https://www.trychroma.com/)'yÄ± kullanacaÄŸÄ±z. Bunu yerel olarak Ã§alÄ±ÅŸtÄ±rabilir ve LangChain aracÄ±lÄ±ÄŸÄ±yla kullanabiliriz.\n",
    "\n",
    "TÃ¼m akÄ±ÅŸÄ±mÄ±zÄ± yeniden oluÅŸturacaÄŸÄ±z. Her ÅŸeyi birkaÃ§ kod hÃ¼cresinde tekrar bir araya getirmeye Ã§alÄ±ÅŸmak iyi bir alÄ±ÅŸtÄ±rmadÄ±r. AynÄ± zamanda her ÅŸeyi yeniden kullanÄ±labilir koda dÃ¶nÃ¼ÅŸtÃ¼receÄŸiz.\n",
    "\n",
    "Sonunda iki fonksiyon istiyoruz:\n",
    "\n",
    "1. `embed_and_store()`: BaÅŸka bir oturumun transkriptini vektÃ¶r veritabanÄ±mÄ±za ekle, bÃ¶ylece alacaÄŸÄ±mÄ±z daha fazla veri olsun.\n",
    "2. `answer()`: VektÃ¶r depomuzla farklÄ± sorularla sorgula."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Bir Chroma vektÃ¶r deposu baÅŸlat\n",
    "\n",
    "ğŸ‘‰ **Veri kalÄ±cÄ±lÄ±ÄŸÄ±yla** (yani verileri diskteki bir dizinde saklayarak) Chroma vektÃ¶r deposunun nasÄ±l oluÅŸturulacaÄŸÄ±nÄ± gÃ¶rmek iÃ§in [LangChain'in belgelerine](https://python.langchain.com/docs/integrations/vectorstores/chroma/) bakÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. `embed_and_store()` oluÅŸtur\n",
    "\n",
    "ğŸ‘‰ Bu fonksiyon iÃ§in kodu tamamlayÄ±n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_and_store(file_path, vector_store):\n",
    "    \"\"\"Load a PDF file, split it into chunks, and store the chunks in a vector store.\"\"\"\n",
    "    # Load the PDF file\n",
    "    pass  # YOUR CODE HERE\n",
    "\n",
    "    # Split the pages into chunks\n",
    "    pass  # YOUR CODE HERE\n",
    "\n",
    "    # # Add the session_date to the metadata\n",
    "    # for split in all_splits:\n",
    "    #     split.metadata['session_date'] = session_date\n",
    "\n",
    "    # Add the chunks to the vector store\n",
    "    pass  # YOUR CODE HERE\n",
    "\n",
    "    return document_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Fonksiyonunuzu bir dosya veya hatta iki dosyayla deneyin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. `answer()` oluÅŸtur\n",
    "\n",
    "ğŸ‘‰ Bu fonksiyon iÃ§in kodu tamamlayÄ±n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def answer(query, vector_store, llm, prompt_template=None):\n",
    "    \"\"\"Answer a query using the vector store and the language model.\"\"\"\n",
    "    # Retrieve similar documents from the vector store\n",
    "    retrieved_docs = vector_store.similarity_search(query, k=6)\n",
    "\n",
    "    # Create the prompt\n",
    "    docs_content = \"\\n\\n\".join(doc.page_content for doc in retrieved_docs)\n",
    "\n",
    "    # If no prompt template is provided, use the default one\n",
    "    if not prompt_template:\n",
    "        prompt_template = hub.pull(\"rlm/rag-prompt\")\n",
    "\n",
    "    prompt = prompt_template.invoke(\n",
    "        {\"context\": docs_content, \"question\": query}\n",
    "    )\n",
    "\n",
    "    # Get the answer from the language model\n",
    "    answer = llm.invoke(prompt)\n",
    "\n",
    "    return answer.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Fonksiyonunuzu beÄŸendiÄŸiniz bir sorguyla deneyin:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ Tebrikler! ArtÄ±k LangChain kullanarak RAG'da ustalaÅŸtÄ±nÄ±z ve vektÃ¶r deponuza daha fazla belge eklemek ve onu sorgulamak iÃ§in yeniden kullanÄ±labilir fonksiyonlar yapmayÄ± Ã¶ÄŸrendiniz."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [Ä°steÄŸe BaÄŸlÄ±] Meta veri ekleme\n",
    "\n",
    "KurduÄŸumuz RAG, vektÃ¶r deposundaki tÃ¼m belgeleri sorgular. Orada birden fazla yÄ±lÄ±n bilgisinin olduÄŸunu dÃ¼ÅŸÃ¼nÃ¼n. YÄ±llara veya tarihlere gÃ¶re filtreyebilsek kullanÄ±ÅŸlÄ± olurdu, deÄŸil mi?\n",
    "\n",
    "Bunu nasÄ±l yaparÄ±z? VektÃ¶r deposundaki belgelerin meta veri iÃ§erdiÄŸini unutmayÄ±n. EÄŸer tarihi ekleyebilseydik, daha sonra filtrelemek iÃ§in kullanabilirdik.\n",
    "\n",
    "Ä°pucu: Meta verilerinizi pipeline'Ä±nÄ±zda olabildiÄŸince erken ekleyin. Verileriniz vektÃ¶r deposunda saklandÄ±ktan sonra eklemeye Ã§alÄ±ÅŸmayÄ±n.\n",
    "\n",
    "ğŸ‘‰ `embed_and_store()` fonksiyonunuzu uyarlayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_and_store_fancy(file_path, vector_store, session_date):\n",
    "    \"\"\"Load a PDF file, split it into chunks, and store the chunks in a vector store.\n",
    "    Session_date is added to the metadata of each chunk.\"\"\"\n",
    "    pass  # YOUR CODE HERE\n",
    "\n",
    "    return document_ids"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ğŸ‘‰ Fonksiyonunuzu deneyin ve vektÃ¶r deponuzun ek meta veri iÃ§erdiÄŸini kontrol edin."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Åimdi alÄ±cÄ±yÄ± kullanÄ±cÄ±nÄ±n sorduÄŸu tarihe gÃ¶re sÄ±nÄ±rlamamÄ±z gerekiyor.\n",
    "\n",
    "ğŸ‘‰ `answer()` fonksiyonunuzu bir tarih alabilecek ve yeni meta verilere dayalÄ± olarak belgeleri filtreleyebilecek ÅŸekilde uyarlayÄ±n."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "challengify"
    ]
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Harika! GÃ¼Ã§lÃ¼ bir RAG sistemi oluÅŸturmak iÃ§in benzerlik aramasÄ±nÄ± meta veri aramasÄ±yla birleÅŸtirdiniz!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
